# BabyLM: Training BPE Tokenizer

This repository contains code for training a tokenizer on [BabyLM](https://github.com/babylm) 10M corpus.
To train a tokenizer, clone this repository, install the requirements and run the following command:
```
python scripts/train_bbpe.py
```
The code is based on [BabyBERTa](https://aclanthology.org/2021.conll-1.49/).
